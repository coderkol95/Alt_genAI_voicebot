{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai as o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # o.api_key = \n",
    "# prompt = \"What is an autoencoder\"\n",
    "# model = \"text-davinci-001\"\n",
    "# response = o.Completion.create(engine=model, prompt=prompt, max_tokens=50)\n",
    "\n",
    "# generated_text = response.choices[0].text\n",
    "# print(generated_text)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hugging face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = os.environ.get(\"HF_KEY\")\n",
    "from langchain import PromptTemplate, HuggingFaceHub, LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/chatbot/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "llm=HuggingFaceHub(repo_id=\"google/flan-t5-large\", model_kwargs={\"temperature\":1e-10})\n",
    "\n",
    "template1 = \"\"\"Question: {question}\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "\n",
    "prompt1 = PromptTemplate(template=template1, input_variables=[\"question\"])\n",
    "question1 = \"When was Google founded?\"\n",
    "chain1 = LLMChain(llm=llm, prompt=prompt1)\n",
    "\n",
    "template2 = \"What other technology companies were founded around {year}?\"\n",
    "prompt2 = PromptTemplate(template=template2, input_variables=[\"year\"])\n",
    "chain2 = LLMChain(llm=llm, prompt=prompt2)\n",
    "\n",
    "template3 = \"Who is the founder of {company}?\"\n",
    "prompt3 = PromptTemplate(template=template3, input_variables=[\"company\"])\n",
    "chain3 = LLMChain(llm=llm, prompt=prompt3)\n",
    "\n",
    "template4 = \"What tehnologies did {founder} work on?\"\n",
    "prompt4 = PromptTemplate(template=template4, input_variables=[\"founder\"])\n",
    "chain4 = LLMChain(llm=llm, prompt=prompt4)\n",
    "\n",
    "template5 = \"What can be done with {tech}?\"\n",
    "prompt5 = PromptTemplate(template=template5, input_variables=[\"tech\"])\n",
    "chain5 = LLMChain(llm=llm, prompt=prompt5)\n",
    "\n",
    "overall_chain = SimpleSequentialChain(chains=[chain1, chain2, chain3, chain4, chain5], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mThe company was founded in 1998. The answer: 1998.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mmicrosoft\u001b[0m\n",
      "\u001b[38;5;200m\u001b[1;3mjohn mcdonald\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mMicrofilm\u001b[0m\n",
      "\u001b[31;1m\u001b[1;3mCan be used to store documents\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Can be used to store documents\n"
     ]
    }
   ],
   "source": [
    "explanation = overall_chain.run(question1)\n",
    "print(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write pytests - > using langchain\n",
    "# Find business use cases where langchain can be used, based on text data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
